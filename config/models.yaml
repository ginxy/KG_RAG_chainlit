models:
  default: deepseek-r1:1.5b
  options:
    - name: deepseek-r1:1.5b
      max_tokens: 8000
      temperature: 0.3
      template: |
        [CONTEXT]
        {context}
        
        [QUESTION]
        {query}
        
        [INSTRUCTIONS]
        - Always use exact names/terms from the context
        - Never shorten or paraphrase names
    - name: llama3.2:3b
      max_tokens: 3000
      temperature: 0.7
    - name: mixtral
      max_tokens: 4000
      temperature: 0.3
      template: |
        [CONTEXT]
        {context}
        
        [QUESTION]
        {query}
    - name: llama3
      max_tokens: 2000
      temperature: 0.7